[
    {
        "id": "openai-gpt4o",
        "provider": "openai",
        "model": "gpt-4o",
        "alias": "GPT-4o",
        "category": "proprietary",
        "family": "GPT-4",
        "release_date": "2024-05",
        "context_length": 128000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.005,
        "cost_per_1k_output_tokens_usd": 0.015,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "general",
        "api_key_env": "OPENAI_API_KEY",
        "import_module": "openai",
        "client_class": "OpenAI",
        "chat_method": "chat.completions.create",
        "extra_args": {
            "model": "gpt-4o",
            "messages": [
                {"role": "system", "content": "{system_prompt}"},
                {"role": "user", "content": "{prompt}"}
            ]
        },
        "notes": "OpenAI's multimodal flagship model. Fast and accurate."
    },
    {
        "id": "openai-o1",
        "provider": "openai",
        "model": "o1",
        "alias": "GPT-o1",
        "category": "proprietary",
        "family": "OpenAI o1",
        "release_date": "2024-09",
        "context_length": 128000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.015,
        "cost_per_1k_output_tokens_usd": 0.06,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "chain-of-thought",
        "api_key_env": "OPENAI_API_KEY",
        "import_module": "openai",
        "client_class": "OpenAI",
        "chat_method": "chat.completions.create",
        "extra_args": {
            "model": "o1",
            "messages": [
                {"role": "system", "content": "{system_prompt}"},
                {"role": "user", "content": "{prompt}"}
            ]
        },
        "notes": "Reasoning-focused successor to GPT-4o. Slower but more logical."
    },
    {
        "id": "anthropic-claude3-opus",
        "provider": "anthropic",
        "model": "claude-3-opus-20240229",
        "alias": "Claude 3 Opus",
        "category": "proprietary",
        "family": "Claude 3",
        "release_date": "2024-02",
        "context_length": 200000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.015,
        "cost_per_1k_output_tokens_usd": 0.075,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "analytical",
        "api_key_env": "ANTHROPIC_API_KEY",
        "import_module": "anthropic",
        "client_class": "Anthropic",
        "chat_method": "messages.create",
        "extra_args": {
            "model": "claude-3-opus-20240229",
            "max_tokens": 1000,
            "messages": [
                {"role": "system", "content": "{system_prompt}"},
                {"role": "user", "content": "{prompt}"}
            ]
        },
        "notes": "Anthropic's top reasoning model with strong reliability."
    },
    {
        "id": "anthropic-claude3-sonnet",
        "provider": "anthropic",
        "model": "claude-3-sonnet-20240229",
        "alias": "Claude 3 Sonnet",
        "category": "proprietary",
        "family": "Claude 3",
        "release_date": "2024-02",
        "context_length": 200000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.003,
        "cost_per_1k_output_tokens_usd": 0.015,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "balanced",
        "api_key_env": "ANTHROPIC_API_KEY",
        "import_module": "anthropic",
        "client_class": "Anthropic",
        "chat_method": "messages.create",
        "extra_args": {
            "model": "claude-3-sonnet-20240229",
            "max_tokens": 1000,
            "messages": [
                {"role": "system", "content": "{system_prompt}"},
                {"role": "user", "content": "{prompt}"}
            ]
        },
        "notes": "Balanced Claude variant — ideal for reasoning vs cost tradeoff."
    },
    {
        "id": "google-gemini15-pro",
        "provider": "google",
        "model": "gemini-1.5-pro",
        "alias": "Gemini 1.5 Pro",
        "category": "proprietary",
        "family": "Gemini 1.5",
        "release_date": "2024-03",
        "context_length": 1000000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.00125,
        "cost_per_1k_output_tokens_usd": 0.005,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "structured",
        "api_key_env": "GOOGLE_API_KEY",
        "import_module": "google.generativeai",
        "client_class": "GenerativeModel",
        "chat_method": "generate_content",
        "extra_args": {},
        "notes": "Extremely long context; excels at structured reasoning tasks."
    },
    {
        "id": "mistral-large",
        "provider": "mistral",
        "model": "mistral-large-latest",
        "alias": "Mistral Large",
        "category": "open-weight",
        "family": "Mistral",
        "release_date": "2024-04",
        "context_length": 32000,
        "max_output_tokens": 2048,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.002,
        "cost_per_1k_output_tokens_usd": 0.006,
        "supports_system_prompt": true,
        "supports_json_mode": false,
        "reasoning_type": "symbolic",
        "api_key_env": "MISTRAL_API_KEY",
        "import_module": "mistralai.client",
        "client_class": "MistralClient",
        "chat_method": "chat",
        "extra_args": {},
        "notes": "Open-weight model with efficient symbolic reasoning performance."
    },
    {
        "id": "huggingface-mixtral8x7b",
        "provider": "huggingface",
        "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "alias": "Mixtral 8×7B",
        "category": "open-weight",
        "family": "Mixtral",
        "release_date": "2023-12",
        "context_length": 32000,
        "max_output_tokens": 2048,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.0,
        "cost_per_1k_output_tokens_usd": 0.0,
        "supports_system_prompt": false,
        "supports_json_mode": false,
        "reasoning_type": "symbolic",
        "api_key_env": "HUGGINGFACE_API_KEY",
        "import_module": "huggingface_hub",
        "client_class": "InferenceClient",
        "chat_method": "text_generation",
        "extra_args": {
            "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "temperature": 0.0,
            "max_new_tokens": 500
        },
        "notes": "Free open-weight MoE model; decent reasoning for its cost."
    },
    {
        "id": "cohere-command-r-plus",
        "provider": "cohere",
        "model": "command-r-plus",
        "alias": "Command R+",
        "category": "proprietary",
        "family": "Command R",
        "release_date": "2024-04",
        "context_length": 128000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.002,
        "cost_per_1k_output_tokens_usd": 0.008,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "retrieval-augmented",
        "api_key_env": "COHERE_API_KEY",
        "import_module": "cohere",
        "client_class": "Client",
        "chat_method": "generate",
        "extra_args": {
            "model": "command-r-plus",
            "temperature": 0.0,
            "max_tokens": 500
        },
        "notes": "RAG-optimized model; strong in retrieval and logical synthesis."
    },
    {
        "id": "deepseek-math-7b",
        "provider": "huggingface",
        "model": "deepseek-ai/deepseek-math-7b",
        "alias": "DeepSeek-Math 7B",
        "category": "research",
        "family": "DeepSeek",
        "release_date": "2024-06",
        "context_length": 16000,
        "max_output_tokens": 1024,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.0,
        "cost_per_1k_output_tokens_usd": 0.0,
        "supports_system_prompt": false,
        "supports_json_mode": false,
        "reasoning_type": "mathematical",
        "api_key_env": "HUGGINGFACE_API_KEY",
        "import_module": "huggingface_hub",
        "client_class": "InferenceClient",
        "chat_method": "text_generation",
        "extra_args": {
            "model": "deepseek-ai/deepseek-math-7b",
            "temperature": 0.0,
            "max_new_tokens": 500
        },
        "notes": "Open math-specialized model; useful for symbolic benchmarking."
    },
    {
        "id": "xai-grok-2",
        "provider": "xai",
        "model": "grok-2",
        "alias": "Grok 2",
        "category": "proprietary",
        "family": "xAI",
        "release_date": "2024-10",
        "context_length": 128000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.004,
        "cost_per_1k_output_tokens_usd": 0.012,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "logical",
        "api_key_env": "XAI_API_KEY",
        "import_module": "xai",
        "client_class": "Client",
        "chat_method": "chat",
        "extra_args": {},
        "notes": "xAI's logic-oriented model; competitive reasoning performance."
    }
]