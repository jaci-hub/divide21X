[
    {
        "id": "openai-gpt4o",
        "provider": "openai",
        "model": "gpt-4o",
        "alias": "GPT-4o",
        "category": "proprietary",
        "family": "GPT-4",
        "release_date": "2024-05",
        "context_length": 128000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.005,
        "cost_per_1k_output_tokens_usd": 0.015,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "general",
        "api_key_env": "OPENAI_API_KEY",
        "import_module": "openai",
        "client_class": "OpenAI",
        "chat_method": "chat.completions.create",
        "extra_args": {
            "model": "gpt-4o",
            "messages": [
                {"role": "system", "content": "{system_prompt}"},
                {"role": "user", "content": "{prompt}"}
            ]
        },
        "notes": "OpenAI's multimodal flagship model. Fast and accurate."
    },
    {
        "id": "openai-o1",
        "provider": "openai",
        "model": "o1",
        "alias": "GPT-o1",
        "category": "proprietary",
        "family": "OpenAI o1",
        "release_date": "2024-09",
        "context_length": 128000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.015,
        "cost_per_1k_output_tokens_usd": 0.06,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "chain-of-thought",
        "api_key_env": "OPENAI_API_KEY",
        "import_module": "openai",
        "client_class": "OpenAI",
        "chat_method": "chat.completions.create",
        "extra_args": {
            "model": "o1",
            "messages": [
                {"role": "system", "content": "{system_prompt}"},
                {"role": "user", "content": "{prompt}"}
            ]
        },
        "notes": "Reasoning-focused successor to GPT-4o. Slower but more logical."
    },
    {
        "id": "anthropic-claude-sonnet-4-5",
        "provider": "anthropic",
        "model": "claude-sonnet-4-5-20250929",
        "alias": "Claude Sonnet 4.5",
        "category": "proprietary",
        "family": "Claude 4",
        "release_date": "2025-09",
        "context_length": 200000,
        "max_output_tokens": 64000,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.003,
        "cost_per_1k_output_tokens_usd": 0.015,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "advanced",
        "api_key_env": "ANTHROPIC_API_KEY",
        "import_module": "anthropic",
        "client_class": "Anthropic",
        "chat_method": "messages.create",
        "extra_args": {
            "model": "claude-sonnet-4-5-20250929",
            "max_tokens": 16000,
            "messages": [
                {"role": "system", "content": "{system_prompt}"},
                {"role": "user", "content": "{prompt}"}
            ]
        },
        "notes": "Anthropic's most capable model as of September 2025; best for complex reasoning, coding and long-horizon agentic tasks."
    },
    {
        "id": "anthropic-claude-haiku-4-5",
        "provider": "anthropic",
        "model": "claude-haiku-4-5-20251001",
        "alias": "Claude Haiku 4.5",
        "category": "proprietary",
        "family": "Claude 4",
        "release_date": "2025-10",
        "context_length": 200000,
        "max_output_tokens": 64000,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.001,
        "cost_per_1k_output_tokens_usd": 0.005,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "fast-balanced",
        "api_key_env": "ANTHROPIC_API_KEY",
        "import_module": "anthropic",
        "client_class": "Anthropic",
        "chat_method": "messages.create",
        "extra_args": {
            "model": "claude-haiku-4-5-20251001",
            "max_tokens": 16000,
            "messages": [
                {"role": "system", "content": "{system_prompt}"},
                {"role": "user", "content": "{prompt}"}
            ]
        },
        "notes": "Anthropic's fastest Claude model in the 4-series; near-frontier intelligence with high throughput and lower cost."
    },
    {
        "id": "anthropic-claude-opus-4-1",
        "provider": "anthropic",
        "model": "claude-opus-4-1-20250805",
        "alias": "Claude Opus 4.1",
        "category": "proprietary",
        "family": "Claude 4",
        "release_date": "2025-08",
        "context_length": 200000,
        "max_output_tokens": 32000,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.015,
        "cost_per_1k_output_tokens_usd": 0.075,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "highest-specialist",
        "api_key_env": "ANTHROPIC_API_KEY",
        "import_module": "anthropic",
        "client_class": "Anthropic",
        "chat_method": "messages.create",
        "extra_args": {
            "model": "claude-opus-4-1-20250805",
            "max_tokens": 1000,
            "messages": [
                {"role": "system", "content": "{system_prompt}"},
                {"role": "user", "content": "{prompt}"}
            ]
        },
        "notes": "Anthropic's specialist model for advanced reasoning and agent workflows; highest capability in the Claude 4 family."
    },
    {
        "id": "google-gemini25-pro",
        "provider": "google",
        "model": "gemini-2.5-pro",
        "alias": "Gemini 2.5 Pro",
        "category": "proprietary",
        "family": "Gemini 2.5",
        "release_date": "2025-03",
        "context_length": 1000000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.00125,
        "cost_per_1k_output_tokens_usd": 0.005,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "structured",
        "api_key_env": "GOOGLE_API_KEY",
        "import_module": "google.generativeai",
        "client_class": "GenerativeModel",
        "chat_method": "generate_content",
        "extra_args": {},
        "notes": "Extremely long context; excels at structured reasoning tasks."
    },
    {
        "id": "mistral-large",
        "provider": "mistral",
        "model": "mistral-large-latest",
        "alias": "Mistral Large",
        "category": "open-weight",
        "family": "Mistral",
        "release_date": "2024-04",
        "context_length": 32000,
        "max_output_tokens": 2048,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.002,
        "cost_per_1k_output_tokens_usd": 0.006,
        "supports_system_prompt": true,
        "supports_json_mode": false,
        "reasoning_type": "symbolic",
        "api_key_env": "MISTRAL_API_KEY",
        "import_module": "mistralai",
        "client_class": "Mistral",
        "chat_method": "chat.complete",
        "extra_args": {
            "model": "mistral-large-latest",
            "messages": [
                {"role": "user", "content": "{prompt}"}
            ]
        },
        "notes": "Open-weight model with efficient symbolic reasoning performance."
    },
    {
        "id": "huggingface-mixtral8x7b",
        "provider": "huggingface",
        "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "alias": "Mixtral 8x7B",
        "category": "open-weight",
        "family": "Mixtral",
        "release_date": "2023-12",
        "context_length": 32000,
        "max_output_tokens": 2048,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.0,
        "cost_per_1k_output_tokens_usd": 0.0,
        "supports_system_prompt": false,
        "supports_json_mode": false,
        "reasoning_type": "symbolic",
        "api_key_env": "HUGGINGFACE_API_KEY",
        "import_module": "huggingface_hub",
        "client_class": "InferenceClient",
        "chat_method": "text_generation",
        "extra_args": {
            "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "temperature": 0.0,
            "max_new_tokens": 500
        },
        "notes": "Free open-weight MoE model; decent reasoning for its cost."
    },
    {
        "id": "llama3-hf",
        "provider": "huggingface",
        "model": "meta-llama/Meta-Llama-3-70B-Instruct",
        "alias": "Llama3 70B HF",
        "category": "open-weight",
        "family": "Llama 3",
        "release_date": "2024-07",
        "context_length": 32768,
        "max_output_tokens": 2048,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.0, 
        "cost_per_1k_output_tokens_usd": 0.0,
        "supports_system_prompt": true, 
        "supports_json_mode": false,
        "reasoning_type": "general", 
        "api_key_env": "HUGGINGFACE_API_KEY",
        "import_module": "huggingface_hub",
        "client_class": "InferenceClient",
        "chat_method": "text_generation",
        "extra_args": {
            "model": "meta-llama/Meta-Llama-3-70B-Instruct",
            "temperature": 0.0,
            "max_new_tokens": 500
        },
        "notes": "Hugging Face Llama 3 instruct model; good for symbolic and reasoning tasks."
    },
    {
        "id": "cohere-command-r-plus",
        "provider": "cohere",
        "model": "command-r-plus",
        "alias": "Command R+",
        "category": "proprietary",
        "family": "Command R",
        "release_date": "2024-04",
        "context_length": 128000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.002,
        "cost_per_1k_output_tokens_usd": 0.008,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "retrieval-augmented",
        "api_key_env": "COHERE_API_KEY",
        "import_module": "cohere",
        "client_class": "Client",
        "chat_method": "chat",
        "extra_args": {
            "model": "command-r-plus",
            "messages": [
                {"role": "user", "content": "{prompt}"}
            ],
            "temperature": 0.0,
            "max_tokens": 500
        },
        "notes": "RAG-optimized model; strong in retrieval and logical synthesis."
    },
    {
        "id": "deepseek-math-7b",
        "provider": "huggingface",
        "model": "deepseek-ai/deepseek-math-7b",
        "alias": "DeepSeek-Math 7B",
        "category": "research",
        "family": "DeepSeek",
        "release_date": "2024-06",
        "context_length": 16000,
        "max_output_tokens": 1024,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.0,
        "cost_per_1k_output_tokens_usd": 0.0,
        "supports_system_prompt": false,
        "supports_json_mode": false,
        "reasoning_type": "mathematical",
        "api_key_env": "HUGGINGFACE_API_KEY",
        "import_module": "huggingface_hub",
        "client_class": "InferenceClient",
        "chat_method": "text_generation",
        "extra_args": {
            "model": "deepseek-ai/deepseek-math-7b",
            "temperature": 0.0,
            "max_new_tokens": 500
        },
        "notes": "Open math-specialized model; useful for symbolic benchmarking."
    },
    {
        "id": "xai-grok-2",
        "provider": "xai",
        "model": "grok-2",
        "alias": "Grok 2",
        "category": "proprietary",
        "family": "xAI",
        "release_date": "2024-10",
        "context_length": 128000,
        "max_output_tokens": 4096,
        "temperature": 0.0,
        "cost_per_1k_input_tokens_usd": 0.004,
        "cost_per_1k_output_tokens_usd": 0.012,
        "supports_system_prompt": true,
        "supports_json_mode": true,
        "reasoning_type": "logical",
        "api_key_env": "XAI_API_KEY",
        "import_module": "xai_sdk",
        "client_class": "Client",
        "chat_method": "chat",
        "extra_args": {
            "model": "grok-2",
            "messages": [
                {"role": "system", "content": "{system_prompt}"},
                {"role": "user", "content": "{prompt}"}
            ]
        },
        "notes": "xAI's logic-oriented model; competitive reasoning performance."
    }
]